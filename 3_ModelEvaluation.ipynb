{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommendation Project\n",
    "\n",
    "This is the third section of the Capstone Project for Udacity's Machine Learning Engineer Nanodegree.\n",
    "\n",
    "This notebook includes importing the saved model from the second notebook, evaluating the accuracy on the test set, and saving model metadata and results into a registry.\n",
    "\n",
    "Author: Ben Walsh \\\n",
    "February 11, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Model Import](#model-import)\n",
    "2. [Evaluate Model](#eval-model)\n",
    "3. [Saving Results](#save-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"model-import\"></a>1. Model Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load latest pickled model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-2021-02-06-17-30-53-334642',\n",
       " 'model-2021-02-07-13-30-55-543499',\n",
       " 'model-2021-02-07-23-53-6-687154',\n",
       " 'model-2021-02-08-23-29-3-205832',\n",
       " 'model-2021-02-11-14-24-33-544871',\n",
       " 'model-2021-02-11-16-25-48-16993',\n",
       " 'model-history.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = './saved_models'\n",
    "os.listdir(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model in pickle\n",
    "model_folder = './saved_models'\n",
    "latest_model = os.listdir(model_folder)[-2]\n",
    "timestamp_str = latest_model.split('model')[-1]\n",
    "xgb_model = pickle.load(open('{}/{}'.format(model_folder, latest_model), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all cleaned feature data: X and y target data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file = './data-input-clean/X_train.csv'\n",
    "X_test_file = './data-input-clean/X_test.csv'\n",
    "y_train_file = './data-input-clean/y_train.csv'\n",
    "y_test_file = './data-input-clean/y_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(X_train_file):\n",
    "    X_train = pd.read_csv(X_train_file)\n",
    "else:\n",
    "    print('Training data file {} not found!'.format(X_train_file))\n",
    "\n",
    "if os.path.exists(y_train_file):\n",
    "    y_train = pd.read_csv(y_train_file)\n",
    "else:\n",
    "    print('Training data file {} not found!'.format(y_train_file))\n",
    "    \n",
    "if os.path.exists(X_test_file):\n",
    "    X_test = pd.read_csv(X_test_file)\n",
    "else:\n",
    "    print('Test data file {} not found!'.format(X_test_file))\n",
    "\n",
    "if os.path.exists(y_test_file):\n",
    "    y_test = pd.read_csv(y_test_file)\n",
    "else:\n",
    "    print('Test data file {} not found!'.format(y_test_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"eval-model\"></a>2. Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = xgb_model.predict(X_train)\n",
    "y_predict_test = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round outputs to compare\n",
    "y_predict_train = y_predict_train.round().reshape(len(y_predict_train),1)\n",
    "y_predict_test = y_predict_test.round().reshape(len(y_predict_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set = 62.30%\n"
     ]
    }
   ],
   "source": [
    "train_acc = (y_predict_train == y_train.values).sum() / len(y_train)\n",
    "print('Accuracy on training set = {:.2f}%'.format(100*train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set = 62.21%\n"
     ]
    }
   ],
   "source": [
    "test_acc = (y_predict_test == y_test.values).sum() / len(y_test)\n",
    "print('Accuracy on testing set = {:.2f}%'.format(100*test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Initial parameters of XGBoost model without any song features in training data and without any new features has accuracy of 61.69%. The accuracy is nearly identical to the training accuracy, indicating the algorithm is not overfitting.\n",
    "\n",
    "Second take of XGBoost model with some song features in training data and without any new features has accuracy of 61.81%, which is only a slight improvement. The accuracy is nearly identical to the training accuracy, indicating the algorithm is not overfitting.\n",
    "\n",
    "Next take attempted to one-hot encode all genres, and simplified to take just the first digit, assuming they were broad categories. Performance dipped slightly to 61.46%. The assumption that they were grouped by first digit is probably wrong.\n",
    "\n",
    "Next take kept features but increased max depth from 5 to 10. As expected, this increased performance. Test accuracy moderately increased to 62.2%. The next takes will revisit genre ID, and consider other hyper-parameter optimization.\n",
    "\n",
    "Age input data was cleaned and objective was adjusted to binary:logistic. This actually slightly decreased test accuracy. In the long run this should be better though and more understandable, since any performance gains from latching on to an age value that was negative or over 200 would not scale to new data.\n",
    "\n",
    "Max depth was increased to 12, balanced by a larger min_child_weight. Record performance (essentially matching the previous high) of 62.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read model registry and retrieve latest model index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'time': '2021-02-06-17-30-53-334642', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date'], 'model-params': {'objective': 'reg:linear', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6166558284115004, 'test-acc': 0.6168999460516007}, '1': {'time': '2021-02-06-17-30-53-334642', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date'], 'model-params': {'objective': 'reg:linear', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6166558284115004, 'test-acc': 0.6168999460516007}, '2': {'time': '2021-02-07-13-30-55-543499', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date', 'song_length', '-1.0', '3.0', '10.0', '17.0', '24.0', '31.0', '38.0', '45.0', '52.0', '59.0', 'genre_ids_num'], 'model-params': {'objective': 'reg:linear', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6176815901721493, 'test-acc': 0.6180777838162879}, '3': {'time': '2021-02-07-23-53-6-687154', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date', 'song_length', '-1.0', '3.0', '10.0', '17.0', '24.0', '31.0', '38.0', '45.0', '52.0', '59.0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'model-params': {'objective': 'reg:linear', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6140951616708311, 'test-acc': 0.6146468539247675}, '4': {'time': '2021-02-08-23-29-3-205832', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date', 'song_length', '-1.0', '3.0', '10.0', '17.0', '24.0', '31.0', '38.0', '45.0', '52.0', '59.0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'model-params': {'objective': 'reg:linear', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6218171673982336, 'test-acc': 0.6217690814048559}, '5': {'time': '-2021-02-11-14-24-33-544871', 'data-features': ['discover', 'explore', 'listen with', 'my library', 'notification', 'radio', 'search', 'settings', 'city', 'bd', 'registered_via', 'registration_init_time', 'expiration_date', 'age_cleaned', 'song_length', '-1.0', '3.0', '10.0', '17.0', '24.0', '31.0', '38.0', '45.0', '52.0', '59.0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'model-params': {'objective': 'binary:logistic', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'alpha': 10, 'n_estimators': 10}, 'train-acc': 0.6198304854171653, 'test-acc': 0.6193782446946637}}\n"
     ]
    }
   ],
   "source": [
    "with open('{}/model-history.json'.format(model_folder), 'r') as openfile: \n",
    "  \n",
    "    # Reading from json file \n",
    "    model_registry = json.load(openfile) \n",
    "    \n",
    "print(model_registry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only taking relevant subset\n",
    "xgb_hyper_params = {'objective': xgb_model.get_params()['objective'],\n",
    "                   'colsample_bytree': xgb_model.get_params()['colsample_bytree'],\n",
    "                   'learning_rate': xgb_model.get_params()['learning_rate'],\n",
    "                   'max_depth': xgb_model.get_params()['max_depth'],\n",
    "                   'alpha': xgb_model.get_params()['alpha'],\n",
    "                   'n_estimators': xgb_model.get_params()['n_estimators']}\n",
    "\n",
    "new_model_index = np.array(list(model_registry.keys())).astype(int).max() + 1;\n",
    "new_model_registry_info = { \\\n",
    "    str(new_model_index) : \\\n",
    "   {\\\n",
    "    'time': timestamp_str,\n",
    "     'data-features': list(X_train.columns.values),\n",
    "    'model-params': xgb_hyper_params,\n",
    "    'train-acc': train_acc, \n",
    "    'test-acc': test_acc \\\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append latest model results and save back to model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry.update(new_model_registry_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/model-history.json'.format(model_folder), 'w') as json_file:\n",
    "    json.dump(model_registry, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out highest score yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = [model_registry[key]['test-acc'] for key in model_registry.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest test accuracy = 0.622 from index = 6\n"
     ]
    }
   ],
   "source": [
    "print('Highest test accuracy = {:.3f} from index = {}'.format(np.max(test_accs), test_accs.index(np.max(test_accs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
